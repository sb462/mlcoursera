<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Mlcoursera : Machine learning project in Coursera Data Science specialization">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Mlcoursera</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/sb462/mlcoursera">View on GitHub</a>

          <h1 id="project_title">Mlcoursera</h1>
          <h2 id="project_tagline">Machine learning project in Coursera Data Science specialization</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/sb462/mlcoursera/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/sb462/mlcoursera/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <hr>

<p>title: Prediction of activity of the subject through analysis of data from wearable
  devices
author: "Sandip Biswas"
date: "Friday, February 20, 2015"</p>

<h2>
<a id="output-html_document" class="anchor" href="#output-html_document" aria-hidden="true"><span class="octicon octicon-link"></span></a>output: html_document</h2>

<h2>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h2>

<p>The group Groupware@LES conducted an experiment and collected data from wearable devices to recognize human activity. The details and the experimental data are given in their <a href="http://groupware.les.inf.puc-rio.br/har">website</a>. The data is collected from different experimental subjects performing excercises in different positions. The goal of this project is to train a model such that from the wearable device data, one can predict the position of excercise.</p>

<h2>
<a id="data-download-and-cleaning" class="anchor" href="#data-download-and-cleaning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data download and cleaning</h2>

<p>We download the data and inspect it.</p>

<div class="highlight highlight-r"><pre><span class="pl-k">if</span>(<span class="pl-k">!</span>file.exists(<span class="pl-s1"><span class="pl-pds">"</span>C:/Users/sandip/Documents/Coursera/course8/HAR.csv<span class="pl-pds">"</span></span>)){
download.file(<span class="pl-v">url</span> <span class="pl-k">=</span><span class="pl-s1"><span class="pl-pds">"</span>http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv<span class="pl-pds">"</span></span>, <span class="pl-v">destfile</span><span class="pl-k">=</span><span class="pl-s1"><span class="pl-pds">"</span>C:/Users/sandip/Documents/Coursera/course8/HAR.csv<span class="pl-pds">"</span></span>, <span class="pl-v">mode</span><span class="pl-k">=</span><span class="pl-s1"><span class="pl-pds">"</span>wb<span class="pl-pds">"</span></span>)
<span class="pl-vo">wearabledata</span> <span class="pl-k">&lt;-</span> read.csv(<span class="pl-v">file</span> <span class="pl-k">=</span> <span class="pl-s1"><span class="pl-pds">"</span>C:/Users/sandip/Documents/Coursera/course8/HAR.csv<span class="pl-pds">"</span></span>, <span class="pl-v">header</span><span class="pl-k">=</span><span class="pl-c1">TRUE</span>, <span class="pl-v">na.strings</span> <span class="pl-k">=</span> c(<span class="pl-s1"><span class="pl-pds">"</span>#DIV/0!<span class="pl-pds">"</span></span>,<span class="pl-s1"><span class="pl-pds">"</span>NA<span class="pl-pds">"</span></span>))
}</pre></div>

<p>We treat the $"classe"$ as response variable and need to decide on a set of predictor variables from $159$ variables. To clean up the data set, we note that there are several missing $NA$ values. To estimate the columns that have large number of $NA$ and remove them.</p>

<div class="highlight highlight-r"><pre><span class="pl-en">percentNA</span> <span class="pl-k">&lt;-</span> <span class="pl-k">function</span>(<span class="pl-vo">vec</span>){
  <span class="pl-vo">NApercent</span> <span class="pl-k">&lt;-</span> round(sum(is.na(<span class="pl-vo">vec</span>))<span class="pl-k">/</span>length(<span class="pl-vo">vec</span>)<span class="pl-k">*</span><span class="pl-c1">100</span>,<span class="pl-c1">1</span>)
  <span class="pl-k">return</span>(<span class="pl-vo">NApercent</span>)
}
<span class="pl-vo">wearable.list</span> <span class="pl-k">&lt;-</span> as.list(<span class="pl-vo">wearabledata</span>)
<span class="pl-vo">NAwearable</span> <span class="pl-k">&lt;-</span> lapply(<span class="pl-v">X</span><span class="pl-k">=</span><span class="pl-vo">wearable.list</span>,<span class="pl-v">FUN</span><span class="pl-k">=</span><span class="pl-vo">percentNA</span>)
<span class="pl-vo">wearableclean</span> <span class="pl-k">&lt;-</span> <span class="pl-vo">wearabledata</span>[,<span class="pl-k">-</span>which(<span class="pl-vo">NAwearable</span><span class="pl-k">&gt;</span><span class="pl-k">=</span><span class="pl-c1">90</span>)]</pre></div>

<h2>
<a id="model-training-" class="anchor" href="#model-training-" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model training </h2>

<p>The number of variables have reduced to $59$. By inspection we see that some of them are related to index, timestamp etc. We do not consider them and consider only the predictor variables that are directly related to $classe$. We consider $user name$ as a predictor variable as we presume same subjects would perform activities in similar fashion and the training model should accomodate that.
We prepare the training dataset and extract a testing data set for cross validation. </p>

<div class="highlight highlight-r"><pre>library(<span class="pl-vo">caret</span>)
set.seed(<span class="pl-c1">12</span>)
<span class="pl-vo">inTrain</span> <span class="pl-k">&lt;-</span> createDataPartition(<span class="pl-v">y</span><span class="pl-k">=</span><span class="pl-vo">wearableclean</span><span class="pl-k">$</span><span class="pl-vo">classe</span>,
                               <span class="pl-v">p</span><span class="pl-k">=</span><span class="pl-c1">0.7</span>, <span class="pl-v">list</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>)
<span class="pl-vo">training</span> <span class="pl-k">&lt;-</span> <span class="pl-vo">wearableclean</span>[<span class="pl-vo">inTrain</span>,][<span class="pl-k">-</span>c(<span class="pl-c1">1</span>,<span class="pl-c1">3</span><span class="pl-k">:</span><span class="pl-c1">7</span>)]
<span class="pl-vo">testing</span> <span class="pl-k">&lt;-</span> <span class="pl-vo">wearableclean</span>[<span class="pl-k">-</span><span class="pl-vo">inTrain</span>,][<span class="pl-k">-</span>c(<span class="pl-c1">1</span>,<span class="pl-c1">3</span><span class="pl-k">:</span><span class="pl-c1">7</span>)]</pre></div>

<p>We train a model based on random forest on the training data set and will cross-validate the model on the validation data set to estimate the out of sample error</p>

<div class="highlight highlight-r"><pre>library(<span class="pl-vo">randomForest</span>)
set.seed(<span class="pl-c1">14</span>)
<span class="pl-vo">rfModel</span> <span class="pl-k">&lt;-</span> randomForest(<span class="pl-v">x</span><span class="pl-k">=</span><span class="pl-vo">training</span>[,<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">53</span>],<span class="pl-v">y</span><span class="pl-k">=</span><span class="pl-vo">training</span>[,<span class="pl-c1">54</span>],<span class="pl-v">mtry</span><span class="pl-k">=</span><span class="pl-c1">8</span>,<span class="pl-v">importance</span><span class="pl-k">=</span><span class="pl-c1">TRUE</span>)</pre></div>

<p>The summary of the random forest model is</p>

<pre><code>## 
## Call:
##  randomForest(x = training[, 1:53], y = training[, 54], mtry = 8,      importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 8
## 
##         OOB estimate of  error rate: 0.52%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 3902    3    1    0    0 0.001024066
## B    7 2646    5    0    0 0.004514673
## C    0   18 2374    4    0 0.009181970
## D    0    0   25 2226    1 0.011545293
## E    0    0    3    5 2517 0.003168317
</code></pre>

<p>The relative influence of different predictors can be explored by looking at their measures</p>

<p><img src="figure/unnamed-chunk-7-1.png" alt="plot of chunk unnamed-chunk-7"> </p>

<h2>
<a id="estimation-of-out-of-sample-error-and-cross-validation" class="anchor" href="#estimation-of-out-of-sample-error-and-cross-validation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Estimation of out of sample error and Cross Validation</h2>

<p>The out of sample error can be estimated by the Out-of-bag error estimate in the randomForest model. The OOB error rate is $0.52$ percent. If we  use the validation set for cross validation, and calculate the confusion matrix,</p>

<div class="highlight highlight-r"><pre><span class="pl-vo">prediction</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-vo">rfModel</span>, <span class="pl-v">newdata</span> <span class="pl-k">=</span> <span class="pl-vo">testing</span>)
<span class="pl-vo">cMatrix</span> <span class="pl-k">&lt;-</span> confusionMatrix(<span class="pl-vo">prediction</span>,<span class="pl-vo">testing</span><span class="pl-k">$</span><span class="pl-vo">classe</span>)
print(<span class="pl-vo">cMatrix</span>)</pre></div>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1673    5    0    0    0
##          B    0 1130    7    0    0
##          C    0    4 1018    8    2
##          D    0    0    1  955    2
##          E    1    0    0    1 1078
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9947          
##                  95% CI : (0.9925, 0.9964)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9933          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9994   0.9921   0.9922   0.9907   0.9963
## Specificity            0.9988   0.9985   0.9971   0.9994   0.9996
## Pos Pred Value         0.9970   0.9938   0.9864   0.9969   0.9981
## Neg Pred Value         0.9998   0.9981   0.9984   0.9982   0.9992
## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
## Detection Rate         0.2843   0.1920   0.1730   0.1623   0.1832
## Detection Prevalence   0.2851   0.1932   0.1754   0.1628   0.1835
## Balanced Accuracy      0.9991   0.9953   0.9947   0.9950   0.9979
</code></pre>

<p>The accuracy of the model is very high, $0.996$, hence the error estimate is very close to the estimated OOB error. We can use this model to predict the activity ("classe") in the testing set.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Mlcoursera maintained by <a href="https://github.com/sb462">sb462</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
