{"name":"Mlcoursera","tagline":"Machine learning project in Coursera Data Science specialization","body":"---\r\ntitle: Prediction of activity of the subject through analysis of data from wearable\r\n  devices\r\nauthor: \"Sandip Biswas\"\r\ndate: \"Friday, February 20, 2015\"\r\noutput: html_document\r\n---\r\n\r\nIntroduction\r\n-------------\r\nThe group Groupware@LES conducted an experiment and collected data from wearable devices to recognize human activity. The details and the experimental data are given in their [website](http://groupware.les.inf.puc-rio.br/har). The data is collected from different experimental subjects performing excercises in different positions. The goal of this project is to train a model such that from the wearable device data, one can predict the position of excercise.\r\n\r\nData download and cleaning\r\n--------------------------\r\nWe download the data and inspect it.\r\n\r\n\r\n```r\r\nif(!file.exists(\"C:/Users/sandip/Documents/Coursera/course8/HAR.csv\")){\r\ndownload.file(url =\"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\", destfile=\"C:/Users/sandip/Documents/Coursera/course8/HAR.csv\", mode=\"wb\")\r\nwearabledata <- read.csv(file = \"C:/Users/sandip/Documents/Coursera/course8/HAR.csv\", header=TRUE, na.strings = c(\"#DIV/0!\",\"NA\"))\r\n}\r\n```\r\nWe treat the $\"classe\"$ as response variable and need to decide on a set of predictor variables from $159$ variables. To clean up the data set, we note that there are several missing $NA$ values. To estimate the columns that have large number of $NA$ and remove them.\r\n\r\n```r\r\npercentNA <- function(vec){\r\n  NApercent <- round(sum(is.na(vec))/length(vec)*100,1)\r\n  return(NApercent)\r\n}\r\nwearable.list <- as.list(wearabledata)\r\nNAwearable <- lapply(X=wearable.list,FUN=percentNA)\r\nwearableclean <- wearabledata[,-which(NAwearable>=90)]\r\n```\r\nModel training \r\n-----------------------------------\r\nThe number of variables have reduced to $59$. By inspection we see that some of them are related to index, timestamp etc. We do not consider them and consider only the predictor variables that are directly related to $classe$. We consider $user name$ as a predictor variable as we presume same subjects would perform activities in similar fashion and the training model should accomodate that.\r\nWe prepare the training dataset and extract a testing data set for cross validation. \r\n\r\n```r\r\nlibrary(caret)\r\nset.seed(12)\r\ninTrain <- createDataPartition(y=wearableclean$classe,\r\n                               p=0.7, list=FALSE)\r\ntraining <- wearableclean[inTrain,][-c(1,3:7)]\r\ntesting <- wearableclean[-inTrain,][-c(1,3:7)]\r\n```\r\nWe train a model based on random forest on the training data set and will cross-validate the model on the validation data set to estimate the out of sample error\r\n\r\n```r\r\nlibrary(randomForest)\r\nset.seed(14)\r\nrfModel <- randomForest(x=training[,1:53],y=training[,54],mtry=8,importance=TRUE)\r\n```\r\nThe summary of the random forest model is\r\n\r\n```\r\n## \r\n## Call:\r\n##  randomForest(x = training[, 1:53], y = training[, 54], mtry = 8,      importance = TRUE) \r\n##                Type of random forest: classification\r\n##                      Number of trees: 500\r\n## No. of variables tried at each split: 8\r\n## \r\n##         OOB estimate of  error rate: 0.52%\r\n## Confusion matrix:\r\n##      A    B    C    D    E class.error\r\n## A 3902    3    1    0    0 0.001024066\r\n## B    7 2646    5    0    0 0.004514673\r\n## C    0   18 2374    4    0 0.009181970\r\n## D    0    0   25 2226    1 0.011545293\r\n## E    0    0    3    5 2517 0.003168317\r\n```\r\nThe relative influence of different predictors can be explored by looking at their measures\r\n\r\n\r\n![plot of chunk unnamed-chunk-7](figure/unnamed-chunk-7-1.png) \r\n\r\nEstimation of out of sample error and Cross Validation\r\n------------------------------------------------------\r\n\r\nThe out of sample error can be estimated by the Out-of-bag error estimate in the randomForest model. The OOB error rate is $0.52$ percent. If we  use the validation set for cross validation, and calculate the confusion matrix,\r\n\r\n```r\r\nprediction <- predict(rfModel, newdata = testing)\r\ncMatrix <- confusionMatrix(prediction,testing$classe)\r\nprint(cMatrix)\r\n```\r\n\r\n```\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction    A    B    C    D    E\r\n##          A 1673    5    0    0    0\r\n##          B    0 1130    7    0    0\r\n##          C    0    4 1018    8    2\r\n##          D    0    0    1  955    2\r\n##          E    1    0    0    1 1078\r\n## \r\n## Overall Statistics\r\n##                                           \r\n##                Accuracy : 0.9947          \r\n##                  95% CI : (0.9925, 0.9964)\r\n##     No Information Rate : 0.2845          \r\n##     P-Value [Acc > NIR] : < 2.2e-16       \r\n##                                           \r\n##                   Kappa : 0.9933          \r\n##  Mcnemar's Test P-Value : NA              \r\n## \r\n## Statistics by Class:\r\n## \r\n##                      Class: A Class: B Class: C Class: D Class: E\r\n## Sensitivity            0.9994   0.9921   0.9922   0.9907   0.9963\r\n## Specificity            0.9988   0.9985   0.9971   0.9994   0.9996\r\n## Pos Pred Value         0.9970   0.9938   0.9864   0.9969   0.9981\r\n## Neg Pred Value         0.9998   0.9981   0.9984   0.9982   0.9992\r\n## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839\r\n## Detection Rate         0.2843   0.1920   0.1730   0.1623   0.1832\r\n## Detection Prevalence   0.2851   0.1932   0.1754   0.1628   0.1835\r\n## Balanced Accuracy      0.9991   0.9953   0.9947   0.9950   0.9979\r\n```\r\nThe accuracy of the model is very high, $0.996$, hence the error estimate is very close to the estimated OOB error. We can use this model to predict the activity (\"classe\") in the testing set.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}