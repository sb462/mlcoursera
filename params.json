{"name":"Mlcoursera","tagline":"Machine learning project in Coursera Data Science specialization","body":"---\r\ntitle: Prediction of activity of the subject through analysis of data from wearable\r\n  devices\r\nauthor: \"Sandip Biswas\"\r\ndate: \"Friday, February 20, 2015\"\r\noutput: html_document\r\n---\r\n\r\nIntroduction\r\n-------------\r\nThe group Groupware@LES conducted an experiment and collected data from wearable devices to recognize human activity. The details and the experimental data are given in their [website](http://groupware.les.inf.puc-rio.br/har). The data is collected from different experimental subjects performing excercises in different positions. The goal of this project is to train a model such that from the wearable device data, one can predict the position of excercise.\r\n\r\nData download and cleaning\r\n--------------------------\r\nWe download the data and inspect it.\r\n\r\n```{r}\r\nif(!file.exists(\"C:/Users/sandip/Documents/Coursera/course8/HAR.csv\")){\r\ndownload.file(url =\"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\", destfile=\"C:/Users/sandip/Documents/Coursera/course8/HAR.csv\", mode=\"wb\")\r\nwearabledata <- read.csv(file = \"C:/Users/sandip/Documents/Coursera/course8/HAR.csv\", header=TRUE, na.strings = c(\"#DIV/0!\",\"NA\"))\r\n}\r\n```\r\nWe treat the $\"classe\"$ as response variable and need to decide on a set of predictor variables from $159$ variables. To clean up the data set, we note that there are several missing $NA$ values. To estimate the columns that have large number of $NA$ and remove them.\r\n```{r}\r\npercentNA <- function(vec){\r\n  NApercent <- round(sum(is.na(vec))/length(vec)*100,1)\r\n  return(NApercent)\r\n}\r\nwearable.list <- as.list(wearabledata)\r\nNAwearable <- lapply(X=wearable.list,FUN=percentNA)\r\nwearableclean <- wearabledata[,-which(NAwearable>=90)]\r\n```\r\nModel training \r\n-----------------------------------\r\nThe number of variables have reduced to $59$. By inspection we see that some of them are related to index, timestamp etc. We do not consider them and consider only the predictor variables that are directly related to $classe$. We consider $user name$ as a predictor variable as we presume same subjects would perform activities in similar fashion and the training model should accomodate that.\r\nWe prepare the training dataset and extract a testing data set for cross validation. \r\n```{r,warning=FALSE,message=FALSE}\r\nlibrary(caret)\r\nset.seed(12)\r\ninTrain <- createDataPartition(y=wearableclean$classe,\r\n                               p=0.7, list=FALSE)\r\ntraining <- wearableclean[inTrain,][-c(1,3:7)]\r\ntesting <- wearableclean[-inTrain,][-c(1,3:7)]\r\n\r\n```\r\nWe train a model based on random forest on the training data set and will cross-validate the model on the validation data set to estimate the out of sample error\r\n```{r, cache=TRUE,warning=FALSE,message=FALSE}\r\nlibrary(randomForest)\r\nset.seed(14)\r\nrfModel <- randomForest(x=training[,1:53],y=training[,54],mtry=8,importance=TRUE)\r\n```\r\nThe summary of the random forest model is\r\n```{r,echo=FALSE}\r\nprint(rfModel)\r\n```\r\nThe relative influence of different predictors can be explored by looking at their measures\r\n\r\n```{r, echo=FALSE,warning=FALSE,message=FALSE}\r\nlibrary(randomForest)\r\nlibrary(data.table)\r\nimportance.measure <-as.data.frame(cbind(rownames(importance(rfModel, type=1)),\r\n                           as.vector(round(importance(rfModel, type=1),1)) ))\r\nsetnames(importance.measure, c(\"predictor_variable\",\"mean_decrease_accuracy\"))\r\nlibrary(dplyr)\r\nimportant.predictor <- arrange(importance.measure,desc(mean_decrease_accuracy))[1:5,]\r\nlibrary(ggplot2)\r\n```\r\n```{r,fig.height=5, fig.width=14,echo=FALSE }\r\nqplot(predictor_variable,mean_decrease_accuracy, data=important.predictor, \r\n      main=\"Relative influence of different predictors on accuracy\", \r\n      sub=\"variable of importance plot\", xlab =\"predictor variables\", \r\n      ylab= \"mean decrease in accuracy\",color = predictor_variable, size=I(5) )\r\n```\r\n\r\nEstimation of out of sample error and Cross Validation\r\n------------------------------------------------------\r\n\r\nThe out of sample error can be estimated by the Out-of-bag error estimate in the randomForest model. The OOB error rate is $0.52$ percent. If we  use the validation set for cross validation, and calculate the confusion matrix,\r\n```{r}\r\nset.seed(15)\r\nprediction <- predict(rfModel, newdata = testing)\r\ncMatrix <- confusionMatrix(prediction,testing$classe)\r\nprint(cMatrix)\r\n```\r\nThe accuracy of the model is very high, $0.995$, hence the error estimate is very close to the estimated OOB error. We can use this model to predict the activity (\"classe\") in the testing set.\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}